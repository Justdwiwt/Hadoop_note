# Hadoop01

## Hadoop概述

Hadoop是基于Google的集群系统理论来进行的开源实现：

Google的集群系统：GFS、MapReduce、BigTable

Hadoop的集群系统：HDFS、MapReduce、HBase

Hadoop设计的初衷是为了解决Nutch的海量数据存储和处理的需求，可以解决大数据场景下的数据存储和处理的问题。一开始HDFS和MapReduce是作为Nutch的两个组件来使用，后来发现这两个组件不只是可以用在Nutch搜索，所以就单独取出来组成了Hadoop。

需要注意的是Hadoop处理的离线数据，即在数据已知以及不要求实时性的场景下使用。

### 传统数据的特点

1. GB、TB级别的数据 
2. 数据增长不快 
3. 主要为结构化的数据 
4. 统计和报表

### 大数据的特点

1. TB、PB级别的数据 

2. 持续的高速增长 

3. 半结构化、非结构化的数据

4. 数据挖掘和预测性分析

5. 海量数据的获取、存储、聚合、管理这些数据以及对数据进行深度分析的新技术和新能力。

> Hadoop名字的起源： Doug Cutting如此解释Hadoop的得名："这个名字是我孩子给一头吃饱了的棕黄色大象命名的。我的命名标准就是简短，容易发音和拼写，没有太多的意义，并且不会被用于别处。小孩子是这方面的高手。Google就是由小孩命名的。"

## 组成

HDFS：用于分布式文件的存储

MapReduce：用于数据的计算

Yarn：进行任务调度。是Hadoop2.0出现的

## Hadoop版本 下载安装

1. 下载地址：http://hadoop.apache.org/releases.html

> Apache Hadoop版本分为三代，我们将第一代Hadoop称为Hadoop 1.0，第二代Hadoop称为Hadoop 2.0。第一代Hadoop包含三个大版本，分别是0.20.x，0.21.x和0.22.x，其中，0.20.x最后演化成1.0.x，变成了稳定版，而0.21.x和0.22.x则NameNode HA等新的重大特性。第二代Hadoop包含两个版本，分别是0.23.x和2.x，它们完全不同于Hadoop 1.0，是一套全新的架构，均包含HDFS Federation和YARN两个系统，相比于0.23.x，2.x增加了NameNode HA和Wire-compatibility两个重大特性

2. 安装

   Hadoop的安装分为单机方式、伪分布式方式 和 完全分布式方式。

   单机模式是Hadoop的默认模式。当首次解压Hadoop的源码包时，Hadoop无法了解硬件安装环境，便保守地选择了最小配置。在这种默认模式下所有3个XML文件均为空。当配置文件为空时，Hadoop会完全运行在本地。因为不需要与其他节点交互，单机模式就不使用HDFS，也不加载任何Hadoop的守护进程。该模式主要用于开发调试MapReduce程序的应用逻辑。

   伪分布模式 Hadoop守护进程运行在本地机器上，模拟一个小规模的的集群。可以使用HDFS和MapReduce

   全分布模式 Hadoop守护进程运行在一个集群上。启动所有的守护进程，具有hadoop完整的功能，可以使用hdfs、mapreduce和yarn，并且这些守护进程运行在集群中，可以真正的利用集群提供高性能，在生产环境下使用

### 伪分布式安装

0. 关闭防火墙

    ```shell
    # 重启后失效

    service iptables start;#立即开启防火墙，但是重启后失效。

    service iptables stop;#立即关闭防火墙，但是重启后失效。

    # 重启后生效 
    chkconfig iptables on;#开启防火墙，重启后生效
    chkconfig iptables off;#关闭防火墙，重启后生效 
    ```

1. 配置主机名

    注意安装hadoop的集群主机名不能有下划线!!不然会找不到主机!无法启动!

    配置主机名

    ```shell
    vi /etc/sysconfig/network
      
    source /etc/sysconfig/network
    ```

    例如：

    ```shell
    NETWORKING=yes

    HOSTNAME=hadoop01
    ```

2. 配置Hosts

    vi /etc/hosts

    填入以下内容

    IP地址 hadoop01

    其他主机和ip对应信息

    <font color="red">注意：</font>如果是Centos7,那么需要再编辑/etc/hostname文件，将其中的内容改为指定的主机名

3. 配置免密码互通

    ```shell
    # 生成自己的公钥和私钥,生成的公私钥将自动存放在/root/.ssh目录下。

    ssh-keygen

    # 把生成的公钥copy到远程机器上

    ssh-copy-id [user]@[host]

    # 此时在远程主机的/root/.ssh/authorized_keys文件中保存了公钥,在known_hosts中保存了已知主机信息，当再次访问的时候就不需要输入密码了。

    ssh [host]

    # 通过此命令远程连接，检验是否可以不需密码连接
    ```

4. 安装JDK

5. 安装hadoop

   通过fz将hadoop安装包上传到linux

   解压安装包 `tar -zxvf [hadoop安装包位置]`

6. 配置hadoop

    1. 修改 hadoop-env.sh

        通过vim打开 `vim [hadoop]/etc/hadoop/hadoop-env.sh`

        主要是修改java_home的路径，在hadoop-env.sh的第27行,把export JAVA_HOME=${JAVA_HOME}修改成具体的路径

        重新加载使修改生效 `source hadoop-env.sh`

    2. 修改 core-site.xml

        通过vim打开 `vim [hadoop]/etc/hadoop/core-site.xml`

        增加namenode配置、文件存储位置配置

        ```xml
        <configuration>
            <property>
                <!--用来指定hdfs的老大，namenode的地址-->
                <name>fs.defaultFS</name>
                <value>hdfs://hadoop01:9000</value>
            </property>
            <property>
                <!--用来指定hadoop运行时产生文件的存放目录-->	
                <name>hadoop.tmp.dir</name> 
                <value>/home/park/work/hadoop-2.7.1/tmp</value>
            </property>
        </configuration>
        ```

    3. 修改 hdfs-site.xml

        通过vim打开	`vim [hadoop]/etc/hadoop/hdfs-site.xml`

        配置包括自身在内的备份副本数量。

        ```xml
        <configuration>
            <property>
            	<!--指定hdfs保存数据副本的数量，包括自己，默认为3-->
            	<!--伪分布式模式，此值必须为1-->
            	<name>dfs.replication</name> 
            	<value>3</value>
            </property>
        </configuration>
        ```

    4. 修改 mapred-site.xml

        说明：在/etc/hadoop的目录下，只有一个mapred-site.xml.template文件，复制一个 `cp mapred-site.xml.template mapred-site.xml`

        通过vim打开	`vim [hadoop]/etc/hadoop/mapred-site.xml`

        配置mapreduce运行在yarn上

        ```xml
        <configuration>
            <property>  
            <!--指定mapreduce运行在yarn上-->
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
            </property>
        </configuration>
        ```

    5. 修改 yarn-site.xml

        通过vim打开 `vim [hadoop]/etc/hadoop/yarn-site.xml`

        配置

        ``` xml
		<configuration>
			<property>
			<!--指定yarn的老大resourcemanager的地址-->
				<name>yarn.resourcemanager.hostname</name>
				<value>hadoop01</value>
			</property>
			<property>
			<!--NodeManager获取数据的方式-->
				<name>yarn.nodemanager.aux-services</name>
				<value>mapreduce_shuffle</value>
			</property>
		</configuration>
        ```

    6. 修改 slaves

        localhost改为对应主机名

    7. 配置hadoop的环境变量

        ```shell
        vim /etc/profile

        export HADOOP_HOME=/home/park/work/hadoop-2.7.1/

        export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin

        # 重新加载profile使配置生效 
        source /etc/profile

        # 环境变量配置完成，测试环境变量是否生效 
        echo $HADOOP_HOME
        ```

    8. 重启linux $reboot

    9. 格式化namenode

        进入 hadoop/bin 输入命令格式化namenode hadoop namenode -format(hdfs namenode -format  以前的方式)

        在格式化的时候，会有这样的输出：`Storage directory /tmp/hadoop-root/dfs/name has been successfully formatted`

7. 启动hadoop

	```shell
   # 在/home/app/hadoop-2.6.0/sbin目录下​	
   start-all.sh
   ```

8. 关闭hadoop

	```shell
   # 在/home/app/hadoop-2.6.0/sbin目录下 
   stop-all.sh
   ```

9. hdfs命令

   hadoop fs -mkdir /user/trunk

   hadoop fs -ls /user

   hadoop fs -lsr /user   (递归的)

   hadoop fs -put test.txt /user/trunk

   hadoop fs -put test.txt .  (复制到hdfs当前目录下，首先要创建当前目录)

   hadoop fs -get /user/trunk/test.txt . (复制到本地当前目录下)

   hadoop fs -cat /user/trunk/test.txt

   hadoop fs -tail /user/trunk/test.txt  (查看最后1000字节)

   hadoop fs -rm /user/trunk/test.txt

   hadoop fs -rmdir /user/trunk

   hadoop fs -help ls (查看ls命令的帮助文档)

10.  通过浏览器访问hadoop管理页面 http://[server_ip]:50070

	 如果访问不了有可能是服务器50070端口被关闭了。通过如下方式打开50070端口:

     service iptables status #查询防火墙状态

     service iptables start #开启防火墙

     iptables -I INPUT -p tcp --dport 80 -j ACCEPT #开通特定端口

     iptables -I INPUT -p tcp --dport 80 -j DROP #关闭特定端口

     service iptables save #保存配置

     service iptables restart #重启防火墙

     * 注意：CentOS 7.0默认使用的是firewall作为防火墙

     查看防火墙状态

     ```shell
     firewall-cmd --state1
     ```

     停止firewall

     ```shell
     systemctl stop firewalld.service1
     ```

     禁止firewall开机启动

     ```shell
     systemctl disable firewalld.service 
     ```
